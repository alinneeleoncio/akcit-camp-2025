## TechAdvisor ‚Äì Seu primeiro agente com LangChain + LangGraph

Um agente simples que recomenda tecnologias para estudar com base no seu interesse. Ele demonstra, de forma did√°tica, como:
- **carregar vari√°veis de ambiente** com `python-dotenv`;
- **construir prompts** com `PromptTemplate` (LangChain);
- **orquestrar um fluxo** com `LangGraph` utilizando um `StateGraph` com n√≥s e arestas;
- **conectar um LLM da OpenAI** via `langchain-openai` usando a interface moderna (LCEL): `prompt | llm | StrOutputParser()`.

### Por que este projeto?
- Ideal para bootcamps e primeiros passos em agentes de IA.
- C√≥digo curto, claro e comentado para facilitar o aprendizado.

---

## Pr√©‚Äërequisitos
- Python 3.12+ (recomendado)
- Conta e chave de API da OpenAI
- macOS, Linux ou Windows com terminal

---

## Setup r√°pido (macOS/Linux)

1) Clonar o reposit√≥rio (ou abrir a pasta no seu ambiente):
```bash
cd /Users/seu-usuario/algum/lugar
git clone <seu-repo>.git
cd akcit/akcit-camp-2025/dia1
```

2) Criar e ativar o ambiente virtual:
```bash
python3 -m venv .venv
source .venv/bin/activate
```

3) Instalar as depend√™ncias espec√≠ficas do agente:
```bash
pip install -r techadvisor/requirements.txt
```

4) Configurar as vari√°veis de ambiente:
```bash
cp .env-sample .env
# edite o arquivo .env e coloque sua chave real
# OPENAI_API_KEY=sk-....
```

> Dica: O arquivo `.env-sample` j√° existe na raiz do projeto. √â s√≥ copiar para `.env` e preencher a chave.

### Windows (PowerShell)
```powershell
py -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install -r techadvisor\requirements.txt
copy .env-sample .env
# edite .env e informe OPENAI_API_KEY
```

---

## Como rodar
Com o ambiente virtual ativo e `.env` configurado:
```bash
python techadvisor/techadvisor_agent.py
```

Exemplo de uso (interativo):
```
ü§ñ TechAdvisor - Recomenda tecnologias com base em seus interesses!

O que voc√™ quer aprender ou melhorar? (ou 'sair'): back-end com Python

üîé Resposta do agente:
Sugest√£o: Estude FastAPI...
------------------------------------------------------------
```

Para sair, digite `sair` (ou `exit`/`quit`).

---

## Como funciona (arquitetura did√°tica)

- `PromptTemplate` (LangChain): define o texto-base com vari√°vel `{interesse}`.
- `ChatOpenAI` (langchain-openai): cria o LLM (modelo da OpenAI) a ser usado.
- `LCEL` (LangChain Expression Language): conectamos `prompt | llm | StrOutputParser()` formando uma pipeline:
  - `prompt` injeta o `{interesse}`
  - `llm` gera a resposta
  - `StrOutputParser()` garante que o resultado final seja string limpa
- `LangGraph`:
  - Criamos um `StateGraph(dict)`, onde o estado √© um dicion√°rio com chaves como `interesse` e `resposta`.
  - Adicionamos um n√≥ `recomendador` que l√™ `interesse`, chama a pipeline e grava `resposta` no estado.
  - Definimos o ponto de entrada e uma aresta para `END` (fluxo simples de 1 passo).

Fluxo resumido:
1) Usu√°rio digita um interesse.
2) O estado entra no n√≥ `recomendador`.
3) A pipeline `prompt | llm | parser` roda e retorna um texto.
4) O texto √© salvo em `state['resposta']` e exibido.

### Diagrama do grafo (Mermaid)

```mermaid
flowchart LR
    entry([Entry Point]) --> R["N√≥: recomendador<br/>(prompt | llm | StrOutputParser)"]
    R --> end([END_NODE])

    %% Anota√ß√µes de estado (conceituais)
    subgraph Estado ["Estado"]
      I["state['interesse']"] 
      O["state['resposta']"]
    end
    
    I -->|input do usu√°rio| R
    R --> O
```

---

## Estrutura dos arquivos
- `techadvisor/techadvisor_agent.py`: c√≥digo do agente (altamente comentado).
- `techadvisor/requirements.txt`: depend√™ncias espec√≠ficas.
- `.env-sample`: modelo de vari√°veis de ambiente (na raiz do projeto).

---

## Personaliza√ß√µes comuns

- **Trocar o modelo**: no arquivo `techadvisor_agent.py`, altere `model="gpt-4o-mini"` para outro modelo compat√≠vel na sua conta.
- **Ajustar criatividade**: modifique `temperature=0.7`.
- **Mudar o prompt**: edite o `template_text` para orientar o agente a outro dom√≠nio (por exemplo, carreiras, cloud, dados, etc.).
- **Adicionar etapas**: crie novos n√≥s no `StateGraph` (por exemplo, um n√≥ que valida a entrada do usu√°rio antes de chamar o LLM) e conecte-os com `add_edge`.

---

## Problemas comuns e solu√ß√µes

- "ModuleNotFoundError: No module named 'langchain_openai'"
  - Rode: `pip install -r techadvisor/requirements.txt` com o venv ativo.

- "API key inv√°lida ou ausente"
  - Verifique seu `.env` e se o terminal tem `OPENAI_API_KEY` carregada. Voc√™ pode testar com `python -c "import os; print(os.getenv('OPENAI_API_KEY'))"`.

- "DeprecationWarning sobre LLMChain"
  - J√° migramos para `prompt | llm | StrOutputParser()`; se notar algo semelhante, confira se est√° rodando a vers√£o mais recente do arquivo.

- Conflitos de vers√µes
  - Atualize depend√™ncias: `pip install -U -r techadvisor/requirements.txt`.
  - Em casos extremos, recrie o venv.

---

## Pr√≥ximos passos sugeridos no bootcamp

- Criar um segundo n√≥ que pe√ßa esclarecimentos quando o interesse for muito gen√©rico.
- Persistir conversas ou m√©tricas com `langsmith`.
- Conectar fontes externas (documentos, web) e usar RAG.
- Adicionar ferramenta de busca e um roteador de n√≥s no `LangGraph`.

---

## Licen√ßa
Projeto educacional para uso em bootcamp. Adapte livremente conforme necess√°rio.


